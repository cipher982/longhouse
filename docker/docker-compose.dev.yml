# Unified Docker Compose for Swarm Platform
#
# PROFILES:
#   zerg  - Zerg only (backend + frontend + postgres), direct port exposure
#   full  - Full platform with nginx reverse proxy (development)
#   prod  - Production mode with security hardening
#
# NOTE: Jarvis chat UI is now part of the Zerg frontend SPA at /chat
#       (no separate jarvis-web service needed)
#
# USAGE:
#   docker compose --profile full up      # Full platform (make dev)
#   docker compose --profile zerg up      # Zerg only (make zerg)
#   docker compose --profile prod up      # Production deployment
#
# REQUIRED ENV VARS (validated by make env-check):
#   POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB
#   OPENAI_API_KEY (for LLM features)
#
# Port configuration via .env:
#   Full profile: JARPXY_PORT (entry point), internal ports auto-configured
#   Zerg profile: BACKEND_PORT, FRONTEND_PORT (direct exposure)

# =============================================================================
# Shared Configuration
# =============================================================================
x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"

x-healthcheck-defaults: &healthcheck-defaults
  interval: 15s
  timeout: 5s
  retries: 3

# =============================================================================
# Services
# =============================================================================
services:
  # ---------------------------------------------------------------------------
  # PostgreSQL Database (always starts - no profile restriction)
  # ---------------------------------------------------------------------------
  # Dev/full profiles: uses named volume (postgres_data)
  # Prod: Override with bind mount to /var/lib/docker/data/swarm/postgres
  postgres:
    image: postgres:16-alpine
    restart: "no"
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - ${POSTGRES_DATA_PATH:-postgres_data}:/var/lib/postgresql/data
      - ../logs/postgres:/var/log/postgresql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - swarm-network
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Zerg Backend - Development (full profile only - internal, behind nginx)
  # ---------------------------------------------------------------------------
  zerg-backend:
    profiles: [full]
    build:
      context: ..
      dockerfile: docker/backend.dockerfile
      target: development
      args:
        BUILD_ENV: development
    restart: "no"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      ENVIRONMENT: development
      MODELS_CONFIG_PATH: /app/config/models.json
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      JWT_SECRET: ${JWT_SECRET:-dev_jwt_secret_change_in_production}
      FERNET_SECRET: ${FERNET_SECRET:-dev_fernet_secret_32_chars_long!}
      TRIGGER_SIGNING_SECRET: ${TRIGGER_SIGNING_SECRET:-dev_trigger_secret}
      AUTH_DISABLED: ${AUTH_DISABLED:-1}
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID:-}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET:-}
      GITHUB_CLIENT_ID: ${GITHUB_CLIENT_ID:-}
      GITHUB_CLIENT_SECRET: ${GITHUB_CLIENT_SECRET:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      JARVIS_DEVICE_SECRET: ${JARVIS_DEVICE_SECRET:-test-secret-for-integration-testing}
      ALLOWED_CORS_ORIGINS: "*"
      LLM_TOKEN_STREAM: ${LLM_TOKEN_STREAM:-true}
      DEV_ADMIN: ${DEV_ADMIN:-1}
      SWARMLET_DATA_PATH: /app/data/workers
      APP_PUBLIC_URL: ${APP_PUBLIC_URL}
      RELOAD: "true"
      DEBUG: "true"
      LOG_LEVEL: DEBUG
    # Port exposure controlled by profile - see zerg-backend-exposed below
    ports: []
    volumes:
      - ../apps/zerg/backend:/app:cached
      - ../config:/app/config:ro
      - backend_static:/app/static
      - ../data:/app/data
      - ${HOME}/.ssh:/home/zerg/.ssh:ro
      - ../logs/backend:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      <<: *healthcheck-defaults
      start_period: 30s
    networks:
      - swarm-network
    logging: *default-logging

  # Zerg Backend with direct port exposure (zerg profile only)
  zerg-backend-exposed:
    profiles: [zerg]
    build:
      context: ..
      dockerfile: docker/backend.dockerfile
      target: development
      args:
        BUILD_ENV: development
    restart: "no"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      ENVIRONMENT: development
      MODELS_CONFIG_PATH: /app/config/models.json
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      JWT_SECRET: ${JWT_SECRET:-dev_jwt_secret_change_in_production}
      FERNET_SECRET: ${FERNET_SECRET:-dev_fernet_secret_32_chars_long!}
      TRIGGER_SIGNING_SECRET: ${TRIGGER_SIGNING_SECRET:-dev_trigger_secret}
      AUTH_DISABLED: ${AUTH_DISABLED:-1}
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID:-}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET:-}
      GITHUB_CLIENT_ID: ${GITHUB_CLIENT_ID:-}
      GITHUB_CLIENT_SECRET: ${GITHUB_CLIENT_SECRET:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      JARVIS_DEVICE_SECRET: ${JARVIS_DEVICE_SECRET:-test-secret-for-integration-testing}
      ALLOWED_CORS_ORIGINS: "*"
      LLM_TOKEN_STREAM: ${LLM_TOKEN_STREAM:-true}
      DEV_ADMIN: ${DEV_ADMIN:-1}
      SWARMLET_DATA_PATH: /app/data/workers
      APP_PUBLIC_URL: ${APP_PUBLIC_URL}
      RELOAD: "true"
      DEBUG: "true"
      LOG_LEVEL: DEBUG
    ports:
      - "${BACKEND_PORT:-47300}:8000"
    volumes:
      - ../apps/zerg/backend:/app:cached
      - ../config:/app/config:ro
      - backend_static:/app/static
      - ../data:/app/data
      - ${HOME}/.ssh:/home/zerg/.ssh:ro
      - ../logs/backend:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      <<: *healthcheck-defaults
      start_period: 30s
    networks:
      - swarm-network
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Zerg Frontend - Development (full profile only - internal, behind nginx)
  # ---------------------------------------------------------------------------
  zerg-frontend:
    profiles: [full]
    build:
      context: ..
      dockerfile: apps/zerg/frontend-web/Dockerfile
      target: development
    restart: "no"
    depends_on:
      - zerg-backend
    environment:
      VITE_API_BASE_URL: ${VITE_API_BASE_URL:-/api}
      VITE_WS_BASE_URL: ${VITE_WS_BASE_URL:-ws://localhost:${JARPXY_PORT:-30080}}
      VITE_AUTH_ENABLED: ${VITE_AUTH_ENABLED:-false}
    # Port exposure controlled by profile - see zerg-frontend-exposed below
    ports: []
    volumes:
      - ../apps/zerg/frontend-web:/app:cached
      - /app/node_modules
      - ../logs/frontend:/app/logs
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:5173/"]
      <<: *healthcheck-defaults
      start_period: 45s
    networks:
      - swarm-network
    logging: *default-logging

  # Zerg Frontend with direct port exposure (zerg profile only)
  zerg-frontend-exposed:
    profiles: [zerg]
    build:
      context: ..
      dockerfile: apps/zerg/frontend-web/Dockerfile
      target: development
    restart: "no"
    depends_on:
      - zerg-backend-exposed
    environment:
      VITE_API_BASE_URL: /api
      VITE_WS_BASE_URL: ws://localhost:${BACKEND_PORT:-47300}
      VITE_AUTH_ENABLED: ${VITE_AUTH_ENABLED:-false}
    ports:
      - "${FRONTEND_PORT:-47200}:5173"
    stop_signal: SIGTERM
    stop_grace_period: 3s
    volumes:
      - ../apps/zerg/frontend-web:/app:cached
      - /app/node_modules
      - ../logs/frontend:/app/logs
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1:5173/"]
      <<: *healthcheck-defaults
      start_period: 45s
    networks:
      - swarm-network
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Nginx Reverse Proxy (full profile only)
  # ---------------------------------------------------------------------------
  # NOTE: jarvis-web service removed - Jarvis chat UI now served by zerg-frontend at /chat
  reverse-proxy:
    profiles: [full]
    image: nginx:alpine
    restart: "no"
    stop_grace_period: 1s
    environment:
      ZERG_BACKEND_PORT: ${ZERG_BACKEND_PORT:-8000}
      ZERG_FRONTEND_PORT: ${ZERG_FRONTEND_PORT:-5173}
      JARPXY_PORT: ${JARPXY_PORT:-30080}
    ports:
      - "${JARPXY_PORT:-30080}:80"
    volumes:
      - ./nginx/docker-compose.unified.conf:/etc/nginx/conf.d/default.conf:ro
      - ../logs/nginx:/var/log/nginx
    depends_on:
      - zerg-frontend
      - zerg-backend
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1/health"]
      <<: *healthcheck-defaults
    networks:
      - swarm-network
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Production Backend (prod profile)
  # ---------------------------------------------------------------------------
  # NOTE: jarvis-web-prod service removed - Jarvis chat UI now served by zerg-frontend at /chat
  zerg-backend-prod:
    profiles: [prod]
    build:
      context: ..
      dockerfile: docker/backend.dockerfile
      target: production
      args:
        BUILD_ENV: production
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      ENVIRONMENT: production
      MODELS_CONFIG_PATH: /app/config/models.json
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      JWT_SECRET: ${JWT_SECRET}
      FERNET_SECRET: ${FERNET_SECRET}
      TRIGGER_SIGNING_SECRET: ${TRIGGER_SIGNING_SECRET}
      AUTH_DISABLED: "0"
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ALLOWED_CORS_ORIGINS: ${ALLOWED_CORS_ORIGINS}
      LLM_TOKEN_STREAM: ${LLM_TOKEN_STREAM:-true}
      DEV_ADMIN: "0"
      APP_PUBLIC_URL: ${APP_PUBLIC_URL}
    volumes:
      - ${BACKEND_STATIC_PATH:-backend_static}:/app/static
      - ../config:/app/config:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - swarm-network
    logging: *default-logging
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

  # ---------------------------------------------------------------------------
  # Production Frontend (prod profile)
  # ---------------------------------------------------------------------------
  zerg-frontend-prod:
    profiles: [prod]
    build:
      context: ..
      dockerfile: apps/zerg/frontend-web/Dockerfile
      target: production
      args:
        # Bake production URLs into build
        VITE_AUTH_ENABLED: "true"
        VITE_API_BASE_URL: "/api"
        VITE_WS_BASE_URL: "${VITE_WS_BASE_URL:-wss://yourdomain.com}"
    restart: unless-stopped
    depends_on:
      - zerg-backend-prod
    healthcheck:
      # Simple health check - just verify nginx is serving
      test: ["CMD", "curl", "-f", "http://localhost:80/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - swarm-network
    logging: *default-logging
    read_only: true
    tmpfs:
      - /var/cache/nginx:noexec,nosuid,size=50m,uid=1000,gid=1000
      - /var/log/nginx:noexec,nosuid,size=10m,uid=1000,gid=1000
      - /var/run:noexec,nosuid,size=10m,uid=1000,gid=1000
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 64M
          cpus: '0.1'

  # ---------------------------------------------------------------------------
  # Production Reverse Proxy (prod profile)
  # ---------------------------------------------------------------------------
  reverse-proxy-prod:
    profiles: [prod]
    image: nginx:alpine
    restart: unless-stopped
    stop_grace_period: 5s
    ports:
      # Production uses standard HTTP/HTTPS ports (or configure via env)
      - "${PROD_HTTP_PORT:-80}:80"
    volumes:
      - ./nginx/docker-compose.prod.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - zerg-frontend-prod
      - zerg-backend-prod
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://127.0.0.1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - swarm-network
    logging: *default-logging

  # ---------------------------------------------------------------------------
  # Dev Runner (full profile) - Simulates user infrastructure
  # ---------------------------------------------------------------------------
  # Starts a runner daemon that connects back to the backend via WebSocket.
  # Tests the runner execution flow locally without external infra.
  # Uses known dev secret from runners.local.json seeding config.
  dev-runner:
    profiles: [full]
    build:
      context: ../apps/runner
      dockerfile: Dockerfile
    restart: "no"
    depends_on:
      zerg-backend:
        condition: service_healthy
    environment:
      SWARMLET_URL: ws://zerg-backend:8000
      RUNNER_NAME: clifford
      RUNNER_SECRET: dev-runner-secret-clifford-12345
      RUNNER_CAPABILITIES: exec.full
    networks:
      - swarm-network
    logging: *default-logging

  # Dev Runner for zerg profile (direct port exposure mode)
  dev-runner-zerg:
    profiles: [zerg]
    build:
      context: ../apps/runner
      dockerfile: Dockerfile
    restart: "no"
    depends_on:
      zerg-backend-exposed:
        condition: service_healthy
    environment:
      SWARMLET_URL: ws://zerg-backend-exposed:8000
      RUNNER_NAME: clifford
      RUNNER_SECRET: dev-runner-secret-clifford-12345
      RUNNER_CAPABILITIES: exec.full
    networks:
      - swarm-network
    logging: *default-logging

# =============================================================================
# Networks
# =============================================================================
networks:
  swarm-network:
    driver: bridge

# =============================================================================
# Volumes
# =============================================================================
# Named volumes for dev/full profiles. For production deployments, set:
#   POSTGRES_DATA_PATH=/var/lib/docker/data/swarm/postgres
#   BACKEND_STATIC_PATH=/var/lib/docker/data/swarm/static
# This enables easier backup management via bind mounts.
volumes:
  postgres_data:
    driver: local
  backend_static:
    driver: local
